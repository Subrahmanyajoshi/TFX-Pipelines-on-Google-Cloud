{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9712edf4-cc65-4102-b660-f1c71255e6eb",
   "metadata": {},
   "source": [
    "## TFX Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bb11a-bb34-4c27-9e66-22d7326cd48e",
   "metadata": {},
   "source": [
    "#### Generate Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21846c83-3f18-4322-a28a-791fb2df3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary commands to unzip the zip file in Google Cloud Storage\n",
    "# ! gsutil -m cp gs://text-analysis-323506/train_data/train_val.zip ./\n",
    "# ! unzip train_val.zip\n",
    "# ! gunzip *.csv.gz\n",
    "# ! gsutil -m mv *.csv gs://text-analysis-323506/train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0821b3-45c2-48bc-bd85-990b2bb56661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install tfx==1.4.0\n",
    "# ! pip install pyparsing==2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf26bac1-ea48-4f6e-a122-62b02243242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import tfx\n",
    "\n",
    "import absl\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow as tf\n",
    "from tfx.components.common_nodes.importer_node import ImporterNode\n",
    "\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2, statistics_pb2, anomalies_pb2\n",
    "from tfx.components import StatisticsGen, CsvExampleGen, SchemaGen, ExampleValidator, Transform\n",
    "\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.components import Tuner\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "from tfx.components.trainer import executor as trainer_executor\n",
    "\n",
    "from tfx.proto import infra_validator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff57fc65-65f5-47b3-a04a-5c5220b5fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e534f21-6a3c-426a-87f9-681ee43e5220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3632fc6f-bc47-4128-b20c-c89a8c19e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://text-analysis-323506/train_data/'\n",
    "ARTIFACT_STORE = os.path.join(os.sep, 'home', 'jupyter', 'artifact-store')\n",
    "SERVING_MODEL_DIR=os.path.join(os.sep, 'home', 'jupyter', 'serving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f485b5-d4df-4e6e-9139-1273a8ae28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'sentiment-analysis'\n",
    "PIPELINE_ROOT = os.path.join('/home/jupyter/', PIPELINE_NAME, time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "os.makedirs(PIPELINE_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b161a9f4-8feb-4cf6-8afb-e47a7e13e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /home/jupyter/sentiment-analysis/20211130_171252/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    metadata_connection_config=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4dfe0f-8613-4aab-b195-adb41b167ce1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798f817-27f5-4916-9776-ef24ee90d435",
   "metadata": {},
   "source": [
    "### CSV Example Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2eff15-6faa-4f8b-8cd9-9890402d2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[        \n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e2a524-ef71-405a-a387-272f759ee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = CsvExampleGen(\n",
    "    input_base=DATA_ROOT,\n",
    "    output_config=output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff90b9-43ca-4a63-afac-8ec27d417f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76579e9c-3a52-4791-8dd3-9c8d37c822e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_uri = example_gen.outputs['examples'].get()[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b17c85-7ebb-4ca0-87ab-523dfb68f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_filenames = [os.path.join(examples_uri, 'Split-train', name)\n",
    "                      for name in os.listdir(os.path.join(examples_uri, 'Split-train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246efa2b-3ded-4193-83df-64efbf2c120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 17:15:06.172454: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f689416-400d-44e4-a2ef-ff8f56963354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [1]\n",
      "input: [b'myattorney home business looking account prose litigant state federal lawsuite maintain hisher files']\n",
      "******\n",
      "input: [b'great book liked book sarah plain tall authors name patricia maclachen characters names caleb sarah anna papa though book interestingit first started caleb siting fire asking questions mama singing songs anna explaining born mama died sarah answered papas letter came live sarah taught caleb swim anybody gets book really enjoy']\n",
      "labels: [0]\n",
      "******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 17:15:06.281215: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for tfrecord in dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(tfrecord.numpy())\n",
    "    for name, feature in example.features.feature.items():\n",
    "        if feature.HasField('bytes_list'):\n",
    "            value = feature.bytes_list.value\n",
    "        if feature.HasField('float_list'):\n",
    "            value = feature.float_list.value\n",
    "        if feature.HasField('int64_list'):\n",
    "            value = feature.int64_list.value\n",
    "        print('{}: {}'.format(name, value))\n",
    "    print('******')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0ae16-ba34-4f5d-83b5-57b38df9f250",
   "metadata": {},
   "source": [
    "#### Train and eval datasets have been created properly !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ee28f-1ef1-47ed-a5f1-0f4a49c839f3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1941434-58e2-412c-8a37-111052bb8d6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistics Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbae01a-a893-4de2-a403-a6a691ab9ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f490db1-4e0e-4d70-9466-6fad8363e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85ed3b-8a37-4415-a88e-dfce6de805e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4737174",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d06f81",
   "metadata": {},
   "source": [
    "### Schema Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec412517",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c69dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed916bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/sentiment-analysis/20211130_171252/SchemaGen/schema/3</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency Domain\n",
       "Feature name                                \n",
       "'input'       BYTES  required  single      -\n",
       "'labels'        INT  required  single      -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a193914",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d90789",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_proto_path = '{}/{}'.format(schema_gen.outputs['schema'].get()[0].uri, 'schema.pbtxt')\n",
    "schema = tfdv.load_schema_text(schema_proto_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff906e40-f2ca-4fde-aaea-2578db6b4f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing domain of feature \"labels\".\n"
     ]
    }
   ],
   "source": [
    "tfdv.set_domain(schema, 'labels', schema_pb2.IntDomain(name='labels', min=0, max=1, is_categorical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36e22fc6-73a7-4f70-98b8-7d9ecd3f83c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>min: 0; max: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency          Domain\n",
       "Feature name                                         \n",
       "'input'       BYTES  required  single               -\n",
       "'labels'        INT  required  single  min: 0; max: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845be53-1502-413d-947c-c816abbaac2c",
   "metadata": {},
   "source": [
    "#### Write schema to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfa51bfc-13ed-400e-9c39-733a4767e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"input\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"labels\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"labels\"\n",
      "    min: 0\n",
      "    max: 1\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "schema_dir = os.path.join(ARTIFACT_STORE, 'schema')\n",
    "tf.io.gfile.makedirs(schema_dir)\n",
    "schema_file = os.path.join(schema_dir, 'schema.pbtxt')\n",
    "\n",
    "tfdv.write_schema_text(schema, schema_file)\n",
    "\n",
    "!cat {schema_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c4022-bf2d-4415-9f47-667781875bec",
   "metadata": {},
   "source": [
    "### Schema Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22a4cdde-4682-49d2-b071-c0c5ce34590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_importer = tfx.dsl.components.common.importer.Importer(\n",
    "      source_uri=schema_dir,\n",
    "      artifact_type=tfx.types.standard_artifacts.Schema).with_id(\n",
    "          'schema_importer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071182aa-d66e-4ceb-aba3-0dd070c1e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661e8e22-77ad-428c-be39-a32bd38c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/artifact-store/schema</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>min: 0; max: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency          Domain\n",
       "Feature name                                         \n",
       "'input'       BYTES  required  single               -\n",
       "'labels'        INT  required  single  min: 0; max: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(schema_importer.outputs['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4847112-74d6-4e10-9b83-b8e9dbc3529d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a17a-2f86-488f-853d-05c06250b368",
   "metadata": {},
   "source": [
    "### ExampleValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e167d8-c3a0-4d8b-95c2-b353cc74e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(    \n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_importer.outputs['result']).with_id(\n",
    "          'example_validator') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c1639-401f-4792-a20c-6ddfcb20036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1eef107-30f4-41de-b778-c2f8ac24f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M\n",
      "\u001c",
      "\n",
      "\u0005input*\u0001\u0010\u00010\u0001r\u000b",
      "\t\u0000\u0000\u0000\u0000\u0000\u0000�?\u0010\u0001\n",
      "-\n",
      "\u0006labels*\u0001\u0010\u00010\u0002J\u000e\n",
      "\u0006labels\u0018\u0000 \u0001(\u0001r\u000b",
      "\t\u0000\u0000\u0000\u0000\u0000\u0000�?\u0010\u00018\u0001"
     ]
    }
   ],
   "source": [
    "train_uri = example_validator.outputs['anomalies'].get()[0].uri\n",
    "train_anomalies_filename = os.path.join(train_uri, \"Split-train/SchemaDiff.pb\")\n",
    "!cat $train_anomalies_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba2681a6-eb8f-48fd-83ab-6f40f9b1c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/sentiment-analysis/20211130_171252/example_validator/anomalies/5</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2a825-12f3-4725-a2d4-1989a4a97b2e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e1d9e-303d-44e0-bb92-8159d40d5c3e",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e7f2ea-83f9-4a23-976e-251e4d032ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_MODULE = 'preprocessing.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c47d398a-df41-40d7-9d22-7560a7df3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    module_file=TRANSFORM_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75eee48-7d12-4a88-88f1-47e4fd9be89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b98e74ed-9840-46c6-a4ed-606c2819ffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/sentiment-analysis/20211130_171252/Transform/transformed_examples/6'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.outputs['transformed_examples'].get()[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1ec01f9-462d-4de2-83a4-8950951bcb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Split-train', 'Split-eval']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(transform.outputs['transformed_examples'].get()[0].uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee660fd7-8d55-498e-ab31-cf0dc7c6fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_uri = transform.outputs['transformed_examples'].get()[0].uri\n",
    "tfrecord_filenames = [os.path.join(transform_uri,  'Split-train', name)\n",
    "                      for name in os.listdir(os.path.join(transform_uri, 'Split-train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb93114f-1bec-4f24-9281-778ec4aabf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_xf: [1]\n",
      "******\n",
      "input_xf: [b'great book liked book sarah plain tall authors name patricia maclachen characters names caleb sarah anna papa though book interestingit first started caleb siting fire asking questions mama singing songs anna explaining born mama died sarah answered papas letter came live sarah taught caleb swim anybody gets book really enjoy']\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "for tfrecord in dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(tfrecord.numpy())\n",
    "    for name, feature in example.features.feature.items():\n",
    "        if feature.HasField('bytes_list'):\n",
    "            value = feature.bytes_list.value\n",
    "        if feature.HasField('float_list'):\n",
    "            value = feature.float_list.value\n",
    "        if feature.HasField('int64_list'):\n",
    "            value = feature.int64_list.value\n",
    "    print('{}: {}'.format(name, value))\n",
    "    print('******')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668332bc-f6da-4d93-b7bf-f45b6013f90c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738b636-b382-4569-97f5-391466086456",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "460844ef-c43a-4270-9ed6-c0fd77c789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_MODULE_FILE = 'model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa6d90ae-3287-49e4-ba38-028fedac5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`custom_executor_spec` is deprecated. Please customize component directly.\n",
      "WARNING:absl:`transformed_examples` is deprecated. Please use `examples` instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    custom_executor_spec=executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n",
    "    module_file=TRAINER_MODULE_FILE,\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=5000),\n",
    "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e44bf9-fddc-4a76-a079-30109b9df414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/sentiment-analysis/20211130_171252/_wheels/tfx_user_code_Trainer-0.0+99359850b23ca73104bd2f3199a77368c1bb0849cbfb17faf56531520364258c-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+99359850b23ca73104bd2f3199a77368c1bb0849cbfb17faf56531520364258c\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2021-11-30 17:42:31.890021: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-30 17:42:31.890075: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-30 17:42:31.891185: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-30 17:42:31.965794: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2021-11-30 17:42:34.520936: W tensorflow/core/framework/op_kernel.cc:1669] OP_REQUIRES failed at cast_op.cc:121 : Unimplemented: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node model/Cast (defined at /threading.py:926) ]] [Op:__inference_train_function_8447]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29693/3279539596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun_if_ipython\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;31m# __IPYTHON__ variable is set by IPython, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;31m# https://ipython.org/ipython-doc/rel-0.10.2/html/interactive/reference.html#embedding-ipython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       absl.logging.warning(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, component, enable_cache, beam_pipeline_args)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mtelemetry_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL_TFX_RUNNER\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrunner_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     }):\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0mexecution_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     return execution_result.ExecutionResult(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/base_component_launcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                          \u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                          copy.deepcopy(execution_decision.exec_properties))\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     absl.logging.info('Running publisher for %s',\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/in_process_component_launcher.py\u001b[0m in \u001b[0;36m_run_executor\u001b[0;34m(self, execution_id, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# output_dict can still be changed, specifically properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     executor.Do(\n\u001b[0;32m---> 74\u001b[0;31m         copy.deepcopy(input_dict), output_dict, copy.deepcopy(exec_properties))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/components/trainer/executor.py\u001b[0m in \u001b[0;36mDo\u001b[0;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mabsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mrun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note: If trained with multi-node distribution workers, it is the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TFX-Pipelines-on-Google-Cloud/pipeline/model.py\u001b[0m in \u001b[0;36mrun_fn\u001b[0;34m(fn_args)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     signatures = {\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node model/Cast (defined at /threading.py:926) ]] [Op:__inference_train_function_8447]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db812d-e4d4-46ae-9ba7-5e92d421bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
