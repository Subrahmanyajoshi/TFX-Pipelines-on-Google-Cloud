{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9712edf4-cc65-4102-b660-f1c71255e6eb",
   "metadata": {},
   "source": [
    "## TFX Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bb11a-bb34-4c27-9e66-22d7326cd48e",
   "metadata": {},
   "source": [
    "#### Generate Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21846c83-3f18-4322-a28a-791fb2df3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary commands to unzip the zip file in Google Cloud Storage\n",
    "# ! gsutil -m cp gs://text-analysis-323506/train_data/train_val.zip ./\n",
    "# ! unzip train_val.zip\n",
    "# ! gunzip *.csv.gz\n",
    "# ! gsutil -m mv *.csv gs://text-analysis-323506/train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0821b3-45c2-48bc-bd85-990b2bb56661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install tfx==1.4.0\n",
    "# ! pip install pyparsing==2.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc206583-2d0c-4996-8f25-b03fa7697d24",
   "metadata": {},
   "source": [
    "__Restart kernel__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf26bac1-ea48-4f6e-a122-62b02243242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tfx\n",
    "\n",
    "import absl\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from tfx.components.common_nodes.importer_node import ImporterNode\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2, statistics_pb2, anomalies_pb2\n",
    "from tfx.components import StatisticsGen, CsvExampleGen, SchemaGen, ExampleValidator, Transform\n",
    "\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.components import Tuner\n",
    "from tfx.dsl.components.base import executor_spec\n",
    "from tfx.components.trainer import executor as trainer_executor\n",
    "\n",
    "from tfx.proto import infra_validator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff57fc65-65f5-47b3-a04a-5c5220b5fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e534f21-6a3c-426a-87f9-681ee43e5220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3632fc6f-bc47-4128-b20c-c89a8c19e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://text-analysis-323506/train_data/'\n",
    "ARTIFACT_STORE = os.path.join(os.sep, 'home', 'jupyter', 'artifact-store')\n",
    "SERVING_MODEL_DIR=os.path.join(os.sep, 'home', 'jupyter', 'serving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f485b5-d4df-4e6e-9139-1273a8ae28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'sentiment-analysis'\n",
    "PIPELINE_ROOT = os.path.join('/home/jupyter/', PIPELINE_NAME, time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "os.makedirs(PIPELINE_ROOT, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b161a9f4-8feb-4cf6-8afb-e47a7e13e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /home/jupyter/sentiment-analysis/20211202_175236/metadata.sqlite.\n"
     ]
    }
   ],
   "source": [
    "context = InteractiveContext(\n",
    "    pipeline_name=PIPELINE_NAME,\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    metadata_connection_config=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4dfe0f-8613-4aab-b195-adb41b167ce1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798f817-27f5-4916-9776-ef24ee90d435",
   "metadata": {},
   "source": [
    "### CSV Example Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2eff15-6faa-4f8b-8cd9-9890402d2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[        \n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e2a524-ef71-405a-a387-272f759ee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = CsvExampleGen(\n",
    "    input_base=DATA_ROOT,\n",
    "    output_config=output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff90b9-43ca-4a63-afac-8ec27d417f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76579e9c-3a52-4791-8dd3-9c8d37c822e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_uri = example_gen.outputs['examples'].get()[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b17c85-7ebb-4ca0-87ab-523dfb68f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_filenames = [os.path.join(examples_uri, 'Split-train', name)\n",
    "                      for name in os.listdir(os.path.join(examples_uri, 'Split-train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246efa2b-3ded-4193-83df-64efbf2c120f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:54:48.494239: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f689416-400d-44e4-a2ef-ff8f56963354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [1]\n",
      "input: [b'myattorney home business looking account prose litigant state federal lawsuite maintain hisher files']\n",
      "******\n",
      "input: [b'great book liked book sarah plain tall authors name patricia maclachen characters names caleb sarah anna papa though book interestingit first started caleb siting fire asking questions mama singing songs anna explaining born mama died sarah answered papas letter came live sarah taught caleb swim anybody gets book really enjoy']\n",
      "labels: [0]\n",
      "******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:54:48.603701: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for tfrecord in dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(tfrecord.numpy())\n",
    "    for name, feature in example.features.feature.items():\n",
    "        if feature.HasField('bytes_list'):\n",
    "            value = feature.bytes_list.value\n",
    "        if feature.HasField('float_list'):\n",
    "            value = feature.float_list.value\n",
    "        if feature.HasField('int64_list'):\n",
    "            value = feature.int64_list.value\n",
    "        print('{}: {}'.format(name, value))\n",
    "    print('******')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0ae16-ba34-4f5d-83b5-57b38df9f250",
   "metadata": {},
   "source": [
    "#### Train and eval datasets have been created properly !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51ee28f-1ef1-47ed-a5f1-0f4a49c839f3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1941434-58e2-412c-8a37-111052bb8d6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistics Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbae01a-a893-4de2-a403-a6a691ab9ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f490db1-4e0e-4d70-9466-6fad8363e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(statistics_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85ed3b-8a37-4415-a88e-dfce6de805e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4737174",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d06f81",
   "metadata": {},
   "source": [
    "### Schema Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec412517",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c69dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed916bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/sentiment-analysis/20211202_175236/SchemaGen/schema/3</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency Domain\n",
       "Feature name                                \n",
       "'input'       BYTES  required  single      -\n",
       "'labels'        INT  required  single      -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a193914",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d90789",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_proto_path = '{}/{}'.format(schema_gen.outputs['schema'].get()[0].uri, 'schema.pbtxt')\n",
    "schema = tfdv.load_schema_text(schema_proto_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff906e40-f2ca-4fde-aaea-2578db6b4f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing domain of feature \"labels\".\n"
     ]
    }
   ],
   "source": [
    "tfdv.set_domain(schema, 'labels', schema_pb2.IntDomain(name='labels', min=0, max=1, is_categorical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36e22fc6-73a7-4f70-98b8-7d9ecd3f83c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>min: 0; max: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency          Domain\n",
       "Feature name                                         \n",
       "'input'       BYTES  required  single               -\n",
       "'labels'        INT  required  single  min: 0; max: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfdv.display_schema(schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6845be53-1502-413d-947c-c816abbaac2c",
   "metadata": {},
   "source": [
    "#### Write schema to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfa51bfc-13ed-400e-9c39-733a4767e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"input\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"labels\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"labels\"\n",
      "    min: 0\n",
      "    max: 1\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "schema_dir = os.path.join(ARTIFACT_STORE, 'schema')\n",
    "tf.io.gfile.makedirs(schema_dir)\n",
    "schema_file = os.path.join(schema_dir, 'schema.pbtxt')\n",
    "\n",
    "tfdv.write_schema_text(schema, schema_file)\n",
    "\n",
    "!cat {schema_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c4022-bf2d-4415-9f47-667781875bec",
   "metadata": {},
   "source": [
    "### Schema Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22a4cdde-4682-49d2-b071-c0c5ce34590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_importer = tfx.dsl.components.common.importer.Importer(\n",
    "      source_uri=schema_dir,\n",
    "      artifact_type=tfx.types.standard_artifacts.Schema).with_id(\n",
    "          'schema_importer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071182aa-d66e-4ceb-aba3-0dd070c1e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(schema_importer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "661e8e22-77ad-428c-be39-a32bd38c63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/artifact-store/schema</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'input'</th>\n",
       "      <td>BYTES</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'labels'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td>single</td>\n",
       "      <td>min: 0; max: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency          Domain\n",
       "Feature name                                         \n",
       "'input'       BYTES  required  single               -\n",
       "'labels'        INT  required  single  min: 0; max: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(schema_importer.outputs['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4847112-74d6-4e10-9b83-b8e9dbc3529d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a17a-2f86-488f-853d-05c06250b368",
   "metadata": {},
   "source": [
    "### ExampleValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e167d8-c3a0-4d8b-95c2-b353cc74e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = ExampleValidator(    \n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_importer.outputs['result']).with_id(\n",
    "          'example_validator') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c1639-401f-4792-a20c-6ddfcb20036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1eef107-30f4-41de-b778-c2f8ac24f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "M\n",
      "\u001c",
      "\n",
      "\u0005input*\u0001\u0010\u00010\u0001r\u000b",
      "\t\u0000\u0000\u0000\u0000\u0000\u0000�?\u0010\u0001\n",
      "-\n",
      "\u0006labels*\u0001\u0010\u00010\u0002J\u000e\n",
      "\u0006labels\u0018\u0000 \u0001(\u0001r\u000b",
      "\t\u0000\u0000\u0000\u0000\u0000\u0000�?\u0010\u00018\u0001"
     ]
    }
   ],
   "source": [
    "train_uri = example_validator.outputs['anomalies'].get()[0].uri\n",
    "train_anomalies_filename = os.path.join(train_uri, \"Split-train/SchemaDiff.pb\")\n",
    "!cat $train_anomalies_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba2681a6-eb8f-48fd-83ab-6f40f9b1c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Artifact at /home/jupyter/sentiment-analysis/20211202_175236/example_validator/anomalies/5</b><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2a825-12f3-4725-a2d4-1989a4a97b2e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e1d9e-303d-44e0-bb92-8159d40d5c3e",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "814c0ee9-dce3-4c8a-ba84-b1856b7cbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://text-analysis-323506/train_data/val_text.csv...\n",
      "/ [1/2 files][190.4 MiB/190.4 MiB]  99% Done                                    \r"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp -r gs://text-analysis-323506/train_data ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "489fa77a-9263-44c7-b0c8-28b3a8e4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_MODULE = 'preprocessing.py'\n",
    "data_path = './train_data/val_text.csv'\n",
    "\n",
    "TOP_K = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd0e26b-e23b-4022-9352-d8151d38d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13da3ce-8fd8-4ecb-8d24-6ed9b5d3b5a8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44600ba-6706-4ec2-9eb4-538523266297",
   "metadata": {},
   "source": [
    "#### Create a tokenizer\n",
    "This should be moved to a custom component. this new component will be responsible for creating a tokenizer and also converting string input to an integer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77f20d8e-927b-46ab-b788-ff71ef53784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d27a8b0a-d0fb-497a-a99e-8fa62081a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529e4f7-0963-4fb1-8db0-fd3e2748078e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "179af17c-b0ab-4461-8951-2c926e00ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "VOCAB_SIZE = 20000\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d373ac5d-8985-4f64-9118-4505cc4d3475",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_vectorize_layer.adapt(list(data['input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9091b-db8f-442c-8006-df6bd3e9c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vectorizer_layer.pickle', 'wb') as handle:\n",
    "    pickle.dump(int_vectorize_layer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f881fb81-1f01-428f-afda-c7dccc2c7d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://vectorizer_layer.pickle [Content-Type=application/octet-stream]...\n",
      "- [1/1 files][ 33.9 MiB/ 33.9 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/33.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil -m cp vectorizer_layer.pickle gs://text-analysis-323506/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c47d398a-df41-40d7-9d22-7560a7df3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    module_file=TRANSFORM_MODULE,\n",
    "    custom_config={'tokenizer_path': 'gs://text-analysis-323506/vectorizer_layer.pickle'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d75eee48-7d12-4a88-88f1-47e4fd9be89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/sentiment-analysis/20211202_175236/_wheels/tfx_user_code_Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068\n",
      "Processing /home/jupyter/sentiment-analysis/20211202_175236/_wheels/tfx_user_code_Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068\n",
      "Processing /home/jupyter/sentiment-analysis/20211202_175236/_wheels/tfx_user_code_Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+73f68bd3f6adf04d6431dc80024bbdad2ef65dccb3ada9fc7d62423eebc1d068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://text-analysis-323506/vectorizer_layer.pickle...\n",
      "- [1/1 files][ 33.9 MiB/ 33.9 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/33.9 MiB.                                     \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"inputs_copy:0\", shape=(None, 2), dtype=int64), values=Tensor(\"inputs_1_copy:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"inputs_2_copy:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     86\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 87\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7f1096267e10>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28870/1436387036.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun_if_ipython\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0;31m# __IPYTHON__ variable is set by IPython, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;31m# https://ipython.org/ipython-doc/rel-0.10.2/html/interactive/reference.html#embedding-ipython.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       absl.logging.warning(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/experimental/interactive/interactive_context.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, component, enable_cache, beam_pipeline_args)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mtelemetry_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL_TFX_RUNNER\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrunner_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     }):\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0mexecution_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     return execution_result.ExecutionResult(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/base_component_launcher.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                          \u001b[0mexecution_decision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                          copy.deepcopy(execution_decision.exec_properties))\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     absl.logging.info('Running publisher for %s',\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/orchestration/launcher/in_process_component_launcher.py\u001b[0m in \u001b[0;36m_run_executor\u001b[0;34m(self, execution_id, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# output_dict can still be changed, specifically properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     executor.Do(\n\u001b[0;32m---> 74\u001b[0;31m         copy.deepcopy(input_dict), output_dict, copy.deepcopy(exec_properties))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/components/transform/executor.py\u001b[0m in \u001b[0;36mDo\u001b[0;34m(self, input_dict, output_dict, exec_properties)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# remove the `_pip_dependencies` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mudf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTempPipInstallContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pip_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0mTransformProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cleaning up temp path %s on executor success'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tfx/components/transform/executor.py\u001b[0m in \u001b[0;36mTransform\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;31m# order to fail faster if it fails.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     analyze_input_columns = tft.get_analyze_input_columns(\n\u001b[0;32m-> 1172\u001b[0;31m         preprocessing_fn, typespecs, force_tf_compat_v1=force_tf_compat_v1)\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     if (disable_statistics and not materialize_output_paths and\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_transform/inspect_preprocessing_fn.py\u001b[0m in \u001b[0;36mget_analyze_input_columns\u001b[0;34m(preprocessing_fn, specs, force_tf_compat_v1)\u001b[0m\n\u001b[1;32m     42\u001b[0m   graph, structured_inputs, _ = (\n\u001b[1;32m     43\u001b[0m       impl_helper.trace_preprocessing_function(\n\u001b[0;32m---> 44\u001b[0;31m           preprocessing_fn, specs, use_tf_compat_v1=use_tf_compat_v1))\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mtensor_sinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTENSOR_REPLACEMENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_transform/impl_helper.py\u001b[0m in \u001b[0;36mtrace_preprocessing_function\u001b[0;34m(preprocessing_fn, input_specs, use_tf_compat_v1, base_temp_dir)\u001b[0m\n\u001b[1;32m    717\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     return _trace_preprocessing_fn_v2(preprocessing_fn, input_specs,\n\u001b[0;32m--> 719\u001b[0;31m                                       base_temp_dir)\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_transform/impl_helper.py\u001b[0m in \u001b[0;36m_trace_preprocessing_fn_v2\u001b[0;34m(preprocessing_fn, specs, base_temp_dir)\u001b[0m\n\u001b[1;32m    683\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mannotators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     concrete_fn = get_traced_transform_fn(\n\u001b[0;32m--> 685\u001b[0;31m         preprocessing_fn, specs, tf_graph_context).get_concrete_function()\n\u001b[0m\u001b[1;32m    686\u001b[0m   return (concrete_fn.graph,\n\u001b[1;32m    687\u001b[0m           \u001b[0mtf2_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_structured_inputs_from_func_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_transform/impl_helper.py\u001b[0m in \u001b[0;36mtransform_fn\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0minputs_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_graph_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m       \u001b[0mtransformed_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m     \u001b[0;31m# An empty `TENSOR_REPLACEMENTS` collection symbolizes that there is no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;31m# analyzer left for Transform to evaluate. Either if this collection is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TFX-Pipelines-on-Google-Cloud/pipeline/preprocessing.py\u001b[0m in \u001b[0;36mpreprocessing_fn\u001b[0;34m(inputs, custom_config)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# int_vectorize_layer.adapt(inputs[Feature.FEATURE_KEY])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFEATURE_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_vectorize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mout\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m   \"\"\"\n\u001b[0;32m--> 437\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   2297\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 2299\u001b[0;31m         \"ExpandDims\", input=input, dim=axis, name=name)\n\u001b[0m\u001b[1;32m   2300\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                          as_ref=False):\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    289\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    551\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    552\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"inputs_copy:0\", shape=(None, 2), dtype=int64), values=Tensor(\"inputs_1_copy:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"inputs_2_copy:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "context.run(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b98e74ed-9840-46c6-a4ed-606c2819ffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/sentiment-analysis/20211201_173227/Transform/transformed_examples/6'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.outputs['transformed_examples'].get()[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1ec01f9-462d-4de2-83a4-8950951bcb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Split-train', 'Split-eval']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(transform.outputs['transformed_examples'].get()[0].uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee660fd7-8d55-498e-ab31-cf0dc7c6fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_uri = transform.outputs['transformed_examples'].get()[0].uri\n",
    "tfrecord_filenames = [os.path.join(transform_uri,  'Split-train', name)\n",
    "                      for name in os.listdir(os.path.join(transform_uri, 'Split-train'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb93114f-1bec-4f24-9281-778ec4aabf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_xf: [1]\n",
      "******\n",
      "input_xf: [b'great book liked book sarah plain tall authors name patricia maclachen characters names caleb sarah anna papa though book interestingit first started caleb siting fire asking questions mama singing songs anna explaining born mama died sarah answered papas letter came live sarah taught caleb swim anybody gets book really enjoy']\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "for tfrecord in dataset.take(2):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(tfrecord.numpy())\n",
    "    for name, feature in example.features.feature.items():\n",
    "        if feature.HasField('bytes_list'):\n",
    "            value = feature.bytes_list.value\n",
    "        if feature.HasField('float_list'):\n",
    "            value = feature.float_list.value\n",
    "        if feature.HasField('int64_list'):\n",
    "            value = feature.int64_list.value\n",
    "    print('{}: {}'.format(name, value))\n",
    "    print('******')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668332bc-f6da-4d93-b7bf-f45b6013f90c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738b636-b382-4569-97f5-391466086456",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "460844ef-c43a-4270-9ed6-c0fd77c789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_MODULE_FILE = 'model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa6d90ae-3287-49e4-ba38-028fedac5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`custom_executor_spec` is deprecated. Please customize component directly.\n",
      "WARNING:absl:`transformed_examples` is deprecated. Please use `examples` instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    custom_executor_spec=executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n",
    "    module_file=TRAINER_MODULE_FILE,\n",
    "    transformed_examples=transform.outputs['transformed_examples'],\n",
    "    schema=schema_importer.outputs['result'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=5000),\n",
    "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e44bf9-fddc-4a76-a079-30109b9df414",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.run(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1db812d-e4d4-46ae-9ba7-5e92d421bf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d698f84-b1dd-4052-8b29-ddd9322a1262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m86",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m86"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
